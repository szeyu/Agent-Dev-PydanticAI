{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Introduction to Pydantic AI\n",
    "\n",
    "In this chapter, we'll introduce Pydantic AI, guide you through its installation and setup, and walk you through creating a simple \"Hello World\" agent using Gemini model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Pydantic AI\n",
    "\n",
    "Pydantic AI is a Python framework designed to simplify the development of production-grade applications utilizing Generative AI. Built by the team behind Pydantic, it offers a model-agnostic approach, supporting various AI models such as OpenAI, Anthropic, Gemini, Deepseek, Ollama, Groq, Cohere, and Mistral. \n",
    "\n",
    "Pydantic AI emphasizes:\n",
    "- Type safety\n",
    "- Structured responses\n",
    "- Seamless integration with tools like Pydantic Logfire for real-time debugging and performance monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Installation and Setup\n",
    "\n",
    "To begin using Pydantic AI, ensure you have Python 3.9 or higher installed. Kindly follow the `README.md` file to install the package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To enable the use of synchronous operations within Jupyter Notebook, you need to import nest_asyncio and apply it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Agent class and set the Google API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Set your Google API key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating a \"Hello World\" Agent\n",
    "\n",
    "Let's create simple agents that respond to basic queries using Gemini model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini Response:\n",
      "Pydantic AI builds upon the solid foundation of Pydantic and provides powerful features specifically designed for building AI applications, particularly those involving language models (LLMs). Here's a breakdown of the key features:\n",
      "\n",
      "**1. Pydantic Model Integration and Validation:**\n",
      "\n",
      "*   **Leverages Pydantic's Strengths:**  At its core, Pydantic AI uses Pydantic's data validation and parsing capabilities.  This means you get automatic data type enforcement, input validation, and serialization/deserialization for your AI model inputs and outputs, ensuring data integrity.\n",
      "*   **Declarative Data Structures:** Define your data structures (input and output schemas) using Python classes with type annotations. This makes your code more readable, maintainable, and self-documenting.\n",
      "*   **Error Handling:**  Pydantic provides detailed error messages when validation fails, making debugging easier. This is crucial when dealing with the potentially unstructured outputs from LLMs.\n",
      "\n",
      "**2. LLM Interaction and Integration:**\n",
      "\n",
      "*   **LLMField:** This is a core component.  It allows you to define fields in your Pydantic models that are automatically populated by an LLM. It handles:\n",
      "    *   **Prompt Generation:**  Automatic generation of prompts based on the model schema and other field values.  You can customize these prompts using Jinja2 templating for precise control.\n",
      "    *   **LLM Execution:**  Seamlessly interacts with LLMs (like OpenAI, Hugging Face, etc.) to execute the generated prompt.\n",
      "    *   **Output Parsing and Validation:** Parses the LLM's response and validates it against the field's data type, ensuring the output conforms to the expected schema.\n",
      "*   **Multi-Model Support:**  Pydantic AI supports various LLMs through integrations with libraries like OpenAI, Hugging Face Transformers, and more. You can configure which LLM to use for different fields or models.\n",
      "*   **Prompt Engineering Tools:** Features designed to help you craft effective prompts, including:\n",
      "    *   **Jinja2 Templating:** Powerful templating to inject variables, conditions, and loops into your prompts, making them dynamic and context-aware.\n",
      "    *   **Prompt Caching:**  Cache LLM responses to reduce costs and latency for repeated requests with the same prompts.\n",
      "    *   **Automatic Retries:** Handles transient errors from LLM providers by automatically retrying requests.\n",
      "\n",
      "**3. Advanced Features for AI Development:**\n",
      "\n",
      "*   **Hydration (Data Enrichment):**  The `Hydrate` class allows you to automatically populate fields in your model by making calls to other LLMs or external APIs.  This enables you to enrich your data and provide more context for subsequent LLM calls.  Example:  Use one LLM to research information about a topic and then pass that information to another LLM to generate a report.\n",
      "*   **Chain of Thought Reasoning:** Supports techniques like Chain-of-Thought prompting to guide LLMs to reason step-by-step, improving the quality of their answers.\n",
      "*   **Function Calling (OpenAI Style):** Allows you to define functions that the LLM can call based on its understanding of the input. This lets the LLM interact with external tools and APIs in a structured way.\n",
      "*   **Tool Use:**  Provides mechanisms to integrate various tools (e.g., search engines, calculators, databases) into your AI workflows, enabling LLMs to perform more complex tasks.\n",
      "*   **Agent Creation:** Simplifies the creation of intelligent agents that can perform tasks by reasoning, planning, and executing actions.\n",
      "*   **Asynchronous Operations:** Supports asynchronous execution for improved performance, especially when interacting with multiple LLMs or APIs.\n",
      "*   **Type Safety and Autocompletion:** Benefit from Python's type system and IDE autocompletion, making your code more robust and easier to develop.\n",
      "\n",
      "**4. Benefits of using Pydantic AI:**\n",
      "\n",
      "*   **Simplified LLM Integration:** Abstracts away much of the complexity of interacting with LLMs.\n",
      "*   **Data Validation and Quality:** Ensures the quality and consistency of data used by your AI models.\n",
      "*   **Code Reusability:**  Pydantic models can be easily reused across different parts of your AI application.\n",
      "*   **Increased Development Speed:**  Reduces boilerplate code and simplifies the development process.\n",
      "*   **Improved Maintainability:**  Clear and declarative code makes your AI applications easier to understand and maintain.\n",
      "*   **Cost Optimization:** Caching and other features help reduce LLM costs.\n",
      "\n",
      "**In essence, Pydantic AI provides a structured and type-safe way to interact with LLMs, enabling you to build robust, reliable, and maintainable AI applications that leverage the power of language models.** It handles the messy details of prompt engineering, LLM interaction, and data validation, allowing you to focus on the core logic of your application.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the agent with Gemini model\n",
    "gemini_agent = Agent(\n",
    "    'google-gla:gemini-2.0-flash',  # Using Gemini 1.5 Flash model\n",
    "    system_prompt='You are a helpful assistant specialized in Python programming.',\n",
    ")\n",
    "\n",
    "# Run the agent with a user query\n",
    "result = gemini_agent.run_sync('What are the key features of Pydantic AI?')\n",
    "print(\"Gemini Response:\")\n",
    "print(result.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Async Usage\n",
    "\n",
    "Pydantic AI also supports asynchronous operations, which is useful for web applications or when making multiple requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini Response:\n",
      "## Structured Outputs in Pydantic AI\n",
      "\n",
      "Pydantic AI simplifies working with AI models by allowing you to define structured outputs using Pydantic models. This provides type safety, validation, and seamless integration with various AI models and tools. Here's a breakdown of how to use structured outputs effectively:\n",
      "\n",
      "**1. Defining Your Output Structure with Pydantic Models**\n",
      "\n",
      "At the core of Pydantic AI's structured output approach is the Pydantic model. You define a class that inherits from `pydantic.BaseModel` and specify the data fields you expect from the AI model along with their corresponding types.\n",
      "\n",
      "```python\n",
      "from pydantic import BaseModel, Field\n",
      "from typing import List\n",
      "\n",
      "class RecipeIngredient(BaseModel):\n",
      "    name: str = Field(description=\"The name of the ingredient\")\n",
      "    quantity: str = Field(description=\"The quantity of the ingredient needed (e.g., '1 cup', '2 tbsp')\")\n",
      "\n",
      "class Recipe(BaseModel):\n",
      "    title: str = Field(description=\"The title of the recipe\")\n",
      "    ingredients: List[RecipeIngredient] = Field(description=\"A list of ingredients and their quantities\")\n",
      "    instructions: str = Field(description=\"Step-by-step instructions to prepare the recipe\")\n",
      "\n",
      "```\n",
      "\n",
      "In this example:\n",
      "\n",
      "- We define two models: `RecipeIngredient` and `Recipe`.\n",
      "- `RecipeIngredient` represents a single ingredient with its name and quantity.\n",
      "- `Recipe` represents a complete recipe with a title, a list of `RecipeIngredient` objects, and instructions.\n",
      "- `Field(description=...)` is used to add descriptions to each field. These descriptions are crucial for guiding the AI model (especially LLMs) during the generation process.\n",
      "\n",
      "**2. Using the Model with Pydantic AI**\n",
      "\n",
      "You would typically use this Pydantic model in conjunction with an AI model invocation, for example, using OpenAI's API through a Pydantic AI tool or function.\n",
      "\n",
      "```python\n",
      "from pydantic_ai import BaseModel, Field\n",
      "from typing import List\n",
      "from openai import OpenAI\n",
      "\n",
      "client = OpenAI()\n",
      "\n",
      "class RecipeIngredient(BaseModel):\n",
      "    name: str = Field(description=\"The name of the ingredient\")\n",
      "    quantity: str = Field(description=\"The quantity of the ingredient needed (e.g., '1 cup', '2 tbsp')\")\n",
      "\n",
      "class Recipe(BaseModel):\n",
      "    title: str = Field(description=\"The title of the recipe\")\n",
      "    ingredients: List[RecipeIngredient] = Field(description=\"A list of ingredients and their quantities\")\n",
      "    instructions: str = Field(description=\"Step-by-step instructions to prepare the recipe\")\n",
      "\n",
      "def generate_recipe(prompt: str) -> Recipe:\n",
      "    \"\"\"Generates a recipe based on a prompt.\n",
      "    \"\"\"\n",
      "    response = client.chat.completions.create(\n",
      "        model=\"gpt-3.5-turbo\",\n",
      "        messages=[\n",
      "            {\"role\": \"user\", \"content\": prompt}\n",
      "        ],\n",
      "        response_model=Recipe\n",
      "    )\n",
      "    return response\n",
      "\n",
      "# Example usage:\n",
      "recipe_prompt = \"Generate a recipe for a chocolate cake.\"\n",
      "recipe = generate_recipe(recipe_prompt)\n",
      "\n",
      "print(f\"Recipe Title: {recipe.title}\")\n",
      "print(\"Ingredients:\")\n",
      "for ingredient in recipe.ingredients:\n",
      "    print(f\"- {ingredient.name}: {ingredient.quantity}\")\n",
      "print(f\"Instructions:\\n{recipe.instructions}\")\n",
      "```\n",
      "\n",
      "In this example:\n",
      "\n",
      "- We define the `generate_recipe` function which takes a prompt as input.\n",
      "- `response_model=Recipe` instructs the OpenAI API to return the output in the structure defined by the `Recipe` Pydantic model.  This is the key part for structured outputs.\n",
      "- After receiving the response, we can access the data directly using `recipe.title`, `recipe.ingredients`, and `recipe.instructions`, benefiting from type safety and autocompletion.\n",
      "\n",
      "**3. Benefits of Using Structured Outputs**\n",
      "\n",
      "- **Type Safety:** Ensures that the AI model's output conforms to the expected data types, reducing errors.\n",
      "- **Data Validation:** Pydantic automatically validates the output based on the field types and any constraints defined in the model.\n",
      "- **Clear Structure:**  Provides a well-defined structure for the AI model's output, making it easier to process and use.\n",
      "- **Contextual Information:**  The `description` fields within the model guide the AI model on what information is expected in each field, leading to more accurate and relevant results.\n",
      "- **Simplified Data Access:**  Allows you to access the generated data using intuitive dot notation (e.g., `recipe.title`).\n",
      "- **Improved Reliability:** By ensuring the output is valid according to the model, you increase the reliability of your AI applications.\n",
      "\n",
      "**4. Advanced Techniques and Considerations**\n",
      "\n",
      "- **Nested Models:**  Use nested models to represent complex data structures.\n",
      "- **Lists and Dictionaries:**  Leverage `List`, `Dict`, and other Python collections within your models.\n",
      "- **Enums:** Use `enum.Enum` to define a fixed set of possible values for a field.\n",
      "- **Validation:** Employ Pydantic's validation features (e.g., `constr`, `conint`, `validator`) to enforce constraints on the data.\n",
      "- **JSON Schema Generation:**  Pydantic can automatically generate a JSON schema from your model, which can be used to define the expected output format for the AI model.  Some AI platforms accept JSON schemas to guide the output.\n",
      "- **Prompt Engineering:**  Craft your prompts to clearly instruct the AI model to generate data that adheres to the structure defined in your Pydantic model.\n",
      "- **Error Handling:** Implement proper error handling to gracefully handle cases where the AI model fails to generate a valid output. This may involve retrying the request with a modified prompt or logging the error for further investigation.\n",
      "\n",
      "**5.  Example with OpenAI Functions (Illustrative)**\n",
      "\n",
      "While the earlier example used `response_model`, OpenAI's function calling offers a more direct way to ensure structured output by defining the function's parameters using the Pydantic model.\n",
      "\n",
      "```python\n",
      "from pydantic import BaseModel, Field\n",
      "from typing import List\n",
      "from openai import OpenAI\n",
      "\n",
      "client = OpenAI()\n",
      "\n",
      "class RecipeIngredient(BaseModel):\n",
      "    name: str = Field(description=\"The name of the ingredient\")\n",
      "    quantity: str = Field(description=\"The quantity of the ingredient needed (e.g., '1 cup', '2 tbsp')\")\n",
      "\n",
      "class Recipe(BaseModel):\n",
      "    title: str = Field(description=\"The title of the recipe\")\n",
      "    ingredients: List[RecipeIngredient] = Field(description=\"A list of ingredients and their quantities\")\n",
      "    instructions: str = Field(description=\"Step-by-step instructions to prepare the recipe\")\n",
      "\n",
      "def generate_recipe(dish_name: str) -> Recipe:\n",
      "    \"\"\"Generates a recipe based on a prompt.\"\"\"\n",
      "    pass  # This is just a placeholder function\n",
      "\n",
      "functions = [\n",
      "    {\n",
      "        \"name\": \"generate_recipe\",\n",
      "        \"description\": \"Generates a recipe based on a dish name.\",\n",
      "        \"parameters\": Recipe.model_json_schema(), # Key: provide schema\n",
      "    }\n",
      "]\n",
      "\n",
      "prompt = \"I want to make a chocolate cake.\"\n",
      "\n",
      "response = client.chat.completions.create(\n",
      "    model=\"gpt-3.5-turbo\",\n",
      "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
      "    functions=functions,\n",
      "    function_call={\"name\": \"generate_recipe\"},  # Force the function call\n",
      ")\n",
      "\n",
      "\n",
      "if response.choices[0].message.function_call:\n",
      "  function_call = response.choices[0].message.function_call\n",
      "  function_name = function_call.name\n",
      "  arguments = json.loads(function_call.arguments)\n",
      "\n",
      "  # The arguments will be a dictionary that matches the Recipe model structure.\n",
      "  recipe = Recipe(**arguments)  # Parse the arguments into the Recipe model.\n",
      "\n",
      "  print(f\"Recipe Title: {recipe.title}\")\n",
      "  print(\"Ingredients:\")\n",
      "  for ingredient in recipe.ingredients:\n",
      "      print(f\"- {ingredient.name}: {ingredient.quantity}\")\n",
      "  print(f\"Instructions:\\n{recipe.instructions}\")\n",
      "else:\n",
      "    print(\"No function call was made.\")\n",
      "```\n",
      "\n",
      "In this OpenAI function calling example,  `Recipe.model_json_schema()`  creates a JSON schema representation of the `Recipe` model. This schema is then passed to the OpenAI API, guiding it to return a response that conforms to this structure.  The arguments returned in `function_call.arguments` can then be parsed directly into the `Recipe` model.\n",
      "\n",
      "By using Pydantic models to define structured outputs, you can significantly improve the reliability, maintainability, and usability of your AI applications. Remember to leverage the description fields within the models to provide clear guidance to the AI model.  Choose the method that best suits your AI platform and application's needs, whether it's `response_model` or function calling.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async def ask_gemini():\n",
    "    # Initialize the agent with Gemini model\n",
    "    agent = Agent(\n",
    "        'google-gla:gemini-2.0-flash',\n",
    "        system_prompt='You are a helpful assistant specialized in Python programming.',\n",
    "    )\n",
    "    \n",
    "    # Run the agent asynchronously\n",
    "    result = await agent.run('Explain how to use structured outputs in Pydantic AI')\n",
    "    print(\"Gemini Response:\")\n",
    "    print(result.data)\n",
    "\n",
    "# Run the async function\n",
    "asyncio.run(ask_gemini())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stream Usage\n",
    "\n",
    "Pydantic AI also supports streaming operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "The \"Hello, world!\" program originates from Brian Kernighan's 1\n",
      "The \"Hello, world!\" program originates from Brian Kernighan's 1972 tutorial, \"A Tutorial Introduction to the Language B.\"  While\n",
      "The \"Hello, world!\" program originates from Brian Kernighan's 1972 tutorial, \"A Tutorial Introduction to the Language B.\"  While not the absolute first instance of a simple introductory program printing text, Kernighan's example was extremely influential and became the standard introductory program for virtually all programming languages.  Its simplicity and immediate demonstrable output made it ideal for teaching fundamental programming concepts.  Before Kernighan's tutorial, similar programs likely existed, but his version cemented its place in programming history.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async def ask_gemini():\n",
    "    # Initialize the agent with Gemini model\n",
    "    agent = Agent(\n",
    "        'google-gla:gemini-1.5-flash',\n",
    "        system_prompt='You are a helpful assistant.',\n",
    "    )\n",
    "    \n",
    "    async with agent.run_stream('Where does \"hello world\" come from?') as result:  \n",
    "        async for message in result.stream_text():  \n",
    "            print(message)\n",
    "\n",
    "# Run the async function\n",
    "asyncio.run(ask_gemini())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample code for streaming response like a chatbot response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-24' coro=<print_stream() running at /tmp/ipykernel_12619/1272130682.py:10>>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"Hello, world!\" program originates from Brian Kernighan's 1972  book, \"A Tutorial Introduction to the Language B.\" While not the very first example program, it became the canonical introductory program in virtually every programming textbook and tutorial thereafter.  Its simplicity and universality cemented its place in programming history.  While earlier examples existed, Kernighan's usage popularized it to the extent it became the standard.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the agent\n",
    "agent = Agent('google-gla:gemini-1.5-flash')\n",
    "\n",
    "async def stream_response(query):\n",
    "    \"\"\"Yield responses from the agent in a streaming manner.\"\"\"\n",
    "    async with agent.run_stream(query) as result:\n",
    "        async for message in result.stream_text(delta=True):  \n",
    "            yield message\n",
    "\n",
    "async def print_stream(query):\n",
    "    \"\"\"Print messages in real-time like a chatbot response.\"\"\"\n",
    "    async for text in stream_response(query):\n",
    "        print(text, end='', flush=True)\n",
    "\n",
    "# Run streaming\n",
    "asyncio.create_task(print_stream('Where does \"hello world\" come from?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Structured Outputs\n",
    "\n",
    "One of the powerful features of Pydantic AI is the ability to get structured responses using Pydantic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tip 1: Accessing Dictionary Values\n",
      "Description: Use square brackets to access values by key.  If the key doesn't exist, a KeyError is raised.\n",
      "Example:\n",
      "my_dict = {\"a\": 1, \"b\": 2}\n",
      "print(my_dict[\"a\"])  # Accessing a value\n",
      "---\n",
      "Tip 2: Checking for Key Existence\n",
      "Description: Check for key existence before access to avoid KeyError exceptions.\n",
      "Example:\n",
      "my_dict = {\"a\": 1, \"b\": 2}\n",
      "if \"a\" in my_dict:\n",
      "    print(my_dict[\"a\"])\n",
      "---\n",
      "Tip 3: Adding or Updating Key-Value Pairs\n",
      "Description: Adding new key-value pairs is straightforward. If the key exists, its value will be updated.\n",
      "Example:\n",
      "my_dict = {\"a\": 1, \"b\": 2}\n",
      "my_dict[\"c\"] = 3\n",
      "print(my_dict)  #Adding a new key-value pair\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "# Define a structured output model\n",
    "class PythonTip(BaseModel):\n",
    "    title: str\n",
    "    description: str\n",
    "    code_example: str\n",
    "\n",
    "class PythonTips(BaseModel):\n",
    "    tips: List[PythonTip]\n",
    "\n",
    "# Initialize the Gemini agent with structured output\n",
    "structured_agent = Agent(\n",
    "    'google-gla:gemini-1.5-flash',\n",
    "    system_prompt='You are a Python expert who provides helpful coding tips.',\n",
    "    result_type=PythonTips\n",
    ")\n",
    "\n",
    "# Get structured response\n",
    "result = structured_agent.run_sync('Give me 3 tips for working with Python dictionaries')\n",
    "\n",
    "# Access the structured data\n",
    "for i, tip in enumerate(result.data.tips, 1):\n",
    "    print(f\"Tip {i}: {tip.title}\")\n",
    "    print(f\"Description: {tip.description}\")\n",
    "    print(f\"Example:\\n{tip.code_example}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this chapter, we've introduced Pydantic AI and demonstrated how to create simple agents using Gemini model. We've also shown how to use structured outputs to get more predictable and type-safe responses from AI models.\n",
    "\n",
    "In the upcoming chapters, we'll delve deeper into building more complex agents, incorporating tools, handling structured responses, and exploring advanced features of Pydantic AI."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
